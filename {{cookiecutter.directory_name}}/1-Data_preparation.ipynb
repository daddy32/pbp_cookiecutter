{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# {{cookiecutter.project_name}}\n",
    "\n",
    "{{cookiecutter.description}}\n",
    "\n",
    "## Data Sources\n",
    "- file1 : Description of where this file came from\n",
    "\n",
    "## Changes\n",
    "- {% now 'utc', '%Y-%m-%d' %} : Started project\n",
    "\n",
    "## Requirements\n",
    "\n",
    "```shell\n",
    "conda install feather-format -c conda-forge\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "## 1. Load phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Locations\n",
    "today = datetime.today()\n",
    "\n",
    "INPUT_DIR = Path.cwd() / 'data'/ '01-input'\n",
    "PROCESSED_DIR = Path.cwd() / 'data'/ '02-processed'\n",
    "\n",
    "# Consider: make input file name one of cookiecutter parameters and use it both here and in the project description.\n",
    "INPUT_FILE = INPUT_DIR / 'FILE1.csv'\n",
    "OUTPUT_FILE = PROCESSED_DIR / f'cleaned_{today:%Y-%m-%d}.feather'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "global df # Workaround against %%time bug. See: https://stackoverflow.com/questions/55341134/variable-scope-is-changed-in-consecutive-cells-using-time-in-jupyter-notebook\n",
    "\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "# or:\n",
    "# df = pd.read_excel(INPUT_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other optional arguments:\n",
    "```python\n",
    "df = pd.read_csv(\n",
    "    INPUT_FILE, \n",
    "    nrows=100000,\n",
    "    dtype={ \n",
    "        'class_1': 'category',\n",
    "        'target_class': 'category'\n",
    "    }\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cleanup phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Preview the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the statistical properties of all features, grouped by values of the selected feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['selected_feature']).agg(['mean', 'count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Column Cleanup\n",
    "\n",
    "- Remove all leading and trailing spaces\n",
    "- Rename the columns for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/30763351/removing-space-in-dataframe-python\n",
    "df.columns = [x.strip() for x in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_rename = {'col1': 'new_name'}\n",
    "df.rename(columns=cols_to_rename, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Clean Up Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix for: Date+time stored as object\n",
    "df['date1'] = df['date1'].astype('datetime64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix for: Boolean stored as object\n",
    "# Step 1\n",
    "distinct_values = df['has_flag'].unique()\n",
    "distinct_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2\n",
    "boolean_values = [True, False, False, True] # Must have same length as distinct_values\n",
    "df['has_flag'] = df['has_flag'].replace(distinct_values, boolean_values)\n",
    "df['has_flag'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative fix for: Boolean stored as object\n",
    "# Works on multiple columns of the same type at once.\n",
    "# Step 1\n",
    "bool_columns = ['has_flag01', 'has_flag02', 'has_flag03', 'has_flag04']\n",
    "# alternative: filter columns by name, using regex:\n",
    "# bool_columns = list(df.filter(regex='^phrase_').columns)\n",
    "\n",
    "values_set = set()\n",
    "\n",
    "for col_name in bool_columns:\n",
    "    distinct_values = set(df[col_name].unique())\n",
    "    values_set = values_set.union(distinct_values)\n",
    "\n",
    "values_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2\n",
    "# Use output from previous cell to create dictionary of replacements\n",
    "replacements = {0: False, 1: True}\n",
    "\n",
    "for col_name in bool_columns:\n",
    "    print('col_name: {}'.format(col_name))\n",
    "    df[col_name] = df[col_name].replace(replacements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Transformation phase\n",
    "### Data Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create derived features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bool feature based on found substring in one of the original features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['new_bool_feature'] = df['original_str_feature'].str.contains('interesting_substring', na=False)\n",
    "df['new_bool_feature'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop redundant or unnecesarry columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\n",
    "    ['col1', 'col2'], \n",
    "    axis=1, \n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Export phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the results\n",
    "\n",
    "Inspect the dataset one last time before the export. \n",
    "Tweak and re-run previous steps if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save output file into processed directory\n",
    "\n",
    "Save a file in the processed directory that is cleaned properly. It will be read in and used later for further analysis.\n",
    "\n",
    "Format options include:\n",
    "- pickle\n",
    "- feather\n",
    "- msgpack\n",
    "- parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_feather(OUTPUT_FILE)\n",
    "# or:\n",
    "# df.to_pickle(OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Notes\n",
    "\n",
    "If the input file is too large, we can do initial inspection of the data and column types on subset of the rows.\n",
    "\n",
    "```python\n",
    "df = pd.read_csv(INPUT_FILE, nrows=x)\n",
    "``` \n",
    "\n",
    "Feather format does not support the compression ([yet](https://stackoverflow.com/a/57685438/401095)), so the output file is still large - approximately as large as the input file in csv format."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
